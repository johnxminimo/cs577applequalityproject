{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de586c61",
   "metadata": {},
   "source": [
    "# Project Deliverable 2 Code\n",
    "For ease of use, I uploaded the csv to github, so the code can be ran easily without downloading the dataset or inserting\n",
    "kaggle api key.\n",
    "\n",
    "## Data Preprocessing and Exploration\n",
    "This section removes any invalid and duplicate entries in our dataset, as well as removing A_id, as it will not be useful for our model. (It is only an identifier.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e2e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1999.500000</td>\n",
       "      <td>-0.503015</td>\n",
       "      <td>-0.989547</td>\n",
       "      <td>-0.470479</td>\n",
       "      <td>0.985478</td>\n",
       "      <td>0.512118</td>\n",
       "      <td>0.498277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1154.844867</td>\n",
       "      <td>1.928059</td>\n",
       "      <td>1.602507</td>\n",
       "      <td>1.943441</td>\n",
       "      <td>1.402757</td>\n",
       "      <td>1.930286</td>\n",
       "      <td>1.874427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.151703</td>\n",
       "      <td>-7.149848</td>\n",
       "      <td>-6.894485</td>\n",
       "      <td>-6.055058</td>\n",
       "      <td>-5.961897</td>\n",
       "      <td>-5.864599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>999.750000</td>\n",
       "      <td>-1.816765</td>\n",
       "      <td>-2.011770</td>\n",
       "      <td>-1.738425</td>\n",
       "      <td>0.062764</td>\n",
       "      <td>-0.801286</td>\n",
       "      <td>-0.771677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999.500000</td>\n",
       "      <td>-0.513703</td>\n",
       "      <td>-0.984736</td>\n",
       "      <td>-0.504758</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.534219</td>\n",
       "      <td>0.503445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2999.250000</td>\n",
       "      <td>0.805526</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>1.894234</td>\n",
       "      <td>1.835976</td>\n",
       "      <td>1.766212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3999.000000</td>\n",
       "      <td>6.406367</td>\n",
       "      <td>5.790714</td>\n",
       "      <td>6.374916</td>\n",
       "      <td>7.619852</td>\n",
       "      <td>7.364403</td>\n",
       "      <td>7.237837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A_id         Size       Weight    Sweetness  Crunchiness  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean   1999.500000    -0.503015    -0.989547    -0.470479     0.985478   \n",
       "std    1154.844867     1.928059     1.602507     1.943441     1.402757   \n",
       "min       0.000000    -7.151703    -7.149848    -6.894485    -6.055058   \n",
       "25%     999.750000    -1.816765    -2.011770    -1.738425     0.062764   \n",
       "50%    1999.500000    -0.513703    -0.984736    -0.504758     0.998249   \n",
       "75%    2999.250000     0.805526     0.030976     0.801922     1.894234   \n",
       "max    3999.000000     6.406367     5.790714     6.374916     7.619852   \n",
       "\n",
       "         Juiciness     Ripeness  \n",
       "count  4000.000000  4000.000000  \n",
       "mean      0.512118     0.498277  \n",
       "std       1.930286     1.874427  \n",
       "min      -5.961897    -5.864599  \n",
       "25%      -0.801286    -0.771677  \n",
       "50%       0.534219     0.503445  \n",
       "75%       1.835976     1.766212  \n",
       "max       7.364403     7.237837  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/johnxminimo/cs577applequalityproject/main/apple_quality.csv'\n",
    "\n",
    "dataset = pd.read_csv(url)\n",
    "dataset.head()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6165be6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.503015</td>\n",
       "      <td>-0.989547</td>\n",
       "      <td>-0.470479</td>\n",
       "      <td>0.985478</td>\n",
       "      <td>0.512118</td>\n",
       "      <td>0.498277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.928059</td>\n",
       "      <td>1.602507</td>\n",
       "      <td>1.943441</td>\n",
       "      <td>1.402757</td>\n",
       "      <td>1.930286</td>\n",
       "      <td>1.874427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.151703</td>\n",
       "      <td>-7.149848</td>\n",
       "      <td>-6.894485</td>\n",
       "      <td>-6.055058</td>\n",
       "      <td>-5.961897</td>\n",
       "      <td>-5.864599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.816765</td>\n",
       "      <td>-2.011770</td>\n",
       "      <td>-1.738425</td>\n",
       "      <td>0.062764</td>\n",
       "      <td>-0.801286</td>\n",
       "      <td>-0.771677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.513703</td>\n",
       "      <td>-0.984736</td>\n",
       "      <td>-0.504758</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.534219</td>\n",
       "      <td>0.503445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.805526</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>1.894234</td>\n",
       "      <td>1.835976</td>\n",
       "      <td>1.766212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.406367</td>\n",
       "      <td>5.790714</td>\n",
       "      <td>6.374916</td>\n",
       "      <td>7.619852</td>\n",
       "      <td>7.364403</td>\n",
       "      <td>7.237837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Size       Weight    Sweetness  Crunchiness    Juiciness  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean     -0.503015    -0.989547    -0.470479     0.985478     0.512118   \n",
       "std       1.928059     1.602507     1.943441     1.402757     1.930286   \n",
       "min      -7.151703    -7.149848    -6.894485    -6.055058    -5.961897   \n",
       "25%      -1.816765    -2.011770    -1.738425     0.062764    -0.801286   \n",
       "50%      -0.513703    -0.984736    -0.504758     0.998249     0.534219   \n",
       "75%       0.805526     0.030976     0.801922     1.894234     1.835976   \n",
       "max       6.406367     5.790714     6.374916     7.619852     7.364403   \n",
       "\n",
       "          Ripeness  \n",
       "count  4000.000000  \n",
       "mean      0.498277  \n",
       "std       1.874427  \n",
       "min      -5.864599  \n",
       "25%      -0.771677  \n",
       "50%       0.503445  \n",
       "75%       1.766212  \n",
       "max       7.237837  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's perform some cleaning/preprocessing (removing duplicates, null/invalid records, and features )\n",
    "# lets first remove duplicates, from our dataset\n",
    "# by looking at the data, we don't need apple_id, as this is just an identifier\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.drop(\"A_id\", axis=1, inplace=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edccd51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       good\n",
      "1       good\n",
      "2        bad\n",
      "3       good\n",
      "4       good\n",
      "        ... \n",
      "3996    good\n",
      "3997     bad\n",
      "3998    good\n",
      "3999    good\n",
      "4000     NaN\n",
      "Name: Quality, Length: 4001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# As shown here, our dataset rates our apple as either good or bad.\n",
    "print(dataset[\"Quality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6910d6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       0.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "3996    1.0\n",
      "3997    0.0\n",
      "3998    1.0\n",
      "3999    1.0\n",
      "4000    NaN\n",
      "Name: Quality, Length: 4001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Instead we should use 1 for good and 0 for bad\n",
    "dataset[\"Quality\"].replace((\"good\", \"bad\"), [1,0], inplace = True)\n",
    "print(dataset[\"Quality\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952b7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Acidity']=pd.to_numeric(dataset.Acidity,errors='coerce')\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930c0f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4000 entries, 0 to 3999\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Size         4000 non-null   float64\n",
      " 1   Weight       4000 non-null   float64\n",
      " 2   Sweetness    4000 non-null   float64\n",
      " 3   Crunchiness  4000 non-null   float64\n",
      " 4   Juiciness    4000 non-null   float64\n",
      " 5   Ripeness     4000 non-null   float64\n",
      " 6   Acidity      4000 non-null   float64\n",
      " 7   Quality      4000 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 281.2 KB\n",
      "          Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
      "0    -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
      "1    -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
      "2    -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
      "3    -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
      "4     1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
      "...        ...       ...        ...          ...        ...       ...   \n",
      "3995  0.059386 -1.067408  -3.714549     0.473052   1.697986  2.244055   \n",
      "3996 -0.293118  1.949253  -0.204020    -0.640196   0.024523 -1.087900   \n",
      "3997 -2.634515 -2.138247  -2.440461     0.657223   2.199709  4.763859   \n",
      "3998 -4.008004 -1.779337   2.366397    -0.200329   2.161435  0.214488   \n",
      "3999  0.278540 -1.715505   0.121217    -1.154075   1.266677 -0.776571   \n",
      "\n",
      "       Acidity  \n",
      "0    -0.491590  \n",
      "1    -0.722809  \n",
      "2     2.621636  \n",
      "3     0.790723  \n",
      "4     0.501984  \n",
      "...        ...  \n",
      "3995  0.137784  \n",
      "3996  1.854235  \n",
      "3997 -1.334611  \n",
      "3998 -2.229720  \n",
      "3999  1.599796  \n",
      "\n",
      "[4000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# now lets begin by splitting our dataset into training and testing\n",
    "X = dataset.drop(\"Quality\", axis = 1)\n",
    "y = dataset[\"Quality\"]\n",
    "dataset.info()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d945d",
   "metadata": {},
   "source": [
    "# Preparing and training our first model (Logistic Reg)\n",
    "For the first model, I opted to train logistic regression, since it is a simple model and could serve as a \"baseline\".\n",
    "\n",
    "The methodolgy I chose is to split the data into training and testing set using a 70/30 split. The reason why I chose this split is becaues we have quite a bit of entries (4000), and should be large enough to where we don't need to add more into our testing set or to use cross validation.\n",
    "\n",
    "I then split the training set into training and tuning, with 20% of the training set going to tuning.\n",
    "\n",
    "As for hyperparamters, I will be using gridsearch in order to test:\n",
    "l1: lasso reg\n",
    "l2: ridge reg\n",
    "\n",
    "regulaization strengths (C): \n",
    "10^-x for x = -5 to 5 (same parameter set from previous homework)\n",
    "\n",
    "solvers:\n",
    "liblinear\n",
    "\n",
    "As for determining whether a model is good, I will use precision since we want to ensure that false positives are at a minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bfe69a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for logistic regression found by GridSearch{'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Precision for log reg on validation set using best parameters found by gridSearch: 0.7673342533707068\n",
      "Precision score on test set: 0.7689393939393939\n",
      "Accuracy score on test set:0.7308333333333333\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "paramGridLR = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear'],\n",
    "}\n",
    "\n",
    "precision_scorer = make_scorer(precision_score, pos_label=1)\n",
    "logRes = LogisticRegression()\n",
    "logResGridSearch = GridSearchCV(estimator=logRes, param_grid = paramGridLR, verbose=1, scoring=precision_scorer)\n",
    "logResGridSearch.fit(X_train, y_train)\n",
    "\n",
    "bestLogResModel = logResGridSearch.best_estimator_\n",
    "precisionOnTest = precision_score(y_test, bestLogResModel.predict(X_test), pos_label=1)\n",
    "\n",
    "\n",
    "print(\"Best parameters for logistic regression found by GridSearch\" + str(logResGridSearch.best_params_))\n",
    "print(\"Precision for log reg on validation set using best parameters found by gridSearch: \" + str(logResGridSearch.best_score_))\n",
    "print(\"Precision score on test set: \" + str(precisionOnTest))\n",
    "print(\"Accuracy score on test set:\" + str(bestLogResModel.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ea20a",
   "metadata": {},
   "source": [
    "## LogReg Results\n",
    "As for the logistic regression results, it seems that the best parameters are: C = 0.01, penalty: l1 (lasso reg).\n",
    "\n",
    "### Test Set\n",
    "Precision score: 0.768\n",
    "Accuracy: 0.73\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b625c",
   "metadata": {},
   "source": [
    "# Training Second Model Random Forest\n",
    "For the second model to test, I opted to use Random Forest.\n",
    "\n",
    "I also chose to use gridsearch inorder to test different hyper parameters like in our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "297534db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "2430 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "974 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'gini', 'log_loss', 'entropy'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "245 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'log_loss', 'entropy', 'gini'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "139 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'entropy', 'gini', 'log_loss'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'gini', 'entropy', 'log_loss'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "177 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'entropy', 'log_loss', 'gini'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "61 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestClassifier must be a str among {'log_loss', 'gini', 'entropy'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "583 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "227 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/johnminimo/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87178571 0.875      0.87107143\n",
      " 0.87321429 0.87214286 0.87321429 0.86678571 0.86571429 0.86964286\n",
      " 0.8725     0.86964286 0.87142857 0.86928571 0.87285714 0.87\n",
      " 0.86464286 0.86785714 0.87       0.86642857 0.86678571 0.86642857\n",
      " 0.86464286 0.86642857 0.87035714 0.86428571 0.86714286 0.86464286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.86464286 0.86642857 0.86464286\n",
      " 0.86178571 0.865      0.86642857 0.86642857 0.8625     0.86392857\n",
      " 0.86285714 0.86821429 0.86392857 0.86357143 0.86285714 0.86535714\n",
      " 0.86035714 0.86428571 0.86321429 0.86607143 0.86428571 0.86214286\n",
      " 0.86107143 0.86428571 0.86428571 0.86392857 0.85892857 0.86285714\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87107143 0.8725     0.87035714\n",
      " 0.87392857 0.87214286 0.87107143 0.87392857 0.86714286 0.86928571\n",
      " 0.86964286 0.86892857 0.87071429 0.86607143 0.86964286 0.87214286\n",
      " 0.86964286 0.86892857 0.87214286 0.86857143 0.86857143 0.86821429\n",
      " 0.86785714 0.8675     0.86785714 0.86464286 0.86857143 0.86678571\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.86571429 0.86964286 0.86785714\n",
      " 0.865      0.86571429 0.86428571 0.86285714 0.86392857 0.86607143\n",
      " 0.86714286 0.85928571 0.86464286 0.85964286 0.86357143 0.86357143\n",
      " 0.865      0.86107143 0.86428571 0.86392857 0.86214286 0.86285714\n",
      " 0.86285714 0.86392857 0.86321429 0.85928571 0.85928571 0.86392857\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.85964286 0.85892857 0.85785714\n",
      " 0.85714286 0.85928571 0.85785714 0.85642857 0.85714286 0.85821429\n",
      " 0.85392857 0.85821429 0.85785714 0.85892857 0.8575     0.85642857\n",
      " 0.8575     0.85535714 0.85964286 0.85642857 0.85714286 0.8575\n",
      " 0.85714286 0.85714286 0.85428571 0.85642857 0.85857143 0.855\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.86107143 0.86535714 0.86285714\n",
      " 0.865      0.86178571 0.86428571 0.86607143 0.86214286 0.86392857\n",
      " 0.86535714 0.85857143 0.86607143 0.86214286 0.8625     0.86535714\n",
      " 0.86214286 0.86107143 0.8625     0.86107143 0.86714286 0.86071429\n",
      " 0.86214286 0.86       0.86464286 0.86428571 0.86357143 0.8625    ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random forest found by GridSearch{'bootstrap': True, 'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision for random forest on validation set using best parameters found by gridSearch: 0.875\n",
      "Precision score on test set: 0.8887070376432079\n",
      "Accuracy score on test set:0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randForestParam = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['mse', 'log_loss']\n",
    "}\n",
    "\n",
    "randomForestGrid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=randForestParam, cv=5, n_jobs = -1)\n",
    "randomForestGrid.fit(X_train, y_train)\n",
    "\n",
    "bestRFModel = randomForestGrid.best_estimator_\n",
    "rfPrecisionOnTest = precision_score(y_test, randomForestGrid.predict(X_test), pos_label=1)\n",
    "\n",
    "\n",
    "print(\"Best parameters for random forest found by GridSearch\" + str(randomForestGrid.best_params_))\n",
    "print(\"Precision for random forest on validation set using best parameters found by gridSearch: \" + str(randomForestGrid.best_score_))\n",
    "print(\"Precision score on test set: \" + str(rfPrecisionOnTest))\n",
    "print(\"Accuracy score on test set:\" + str(bestRFModel.score(X_test, y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57defaed",
   "metadata": {},
   "source": [
    "## Results on Random Forest\n",
    "For random forest results, it seems that the best parameters are:{'bootstrap': True, 'criterion': 'log_loss', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}.\n",
    "\n",
    "### Test Set\n",
    "Precision score: 0.89\n",
    "Accuracy: 0.89\n",
    "\n",
    "Our precision score and accuracy score both do better compared to our first baseline model.\n",
    "\n",
    "With a precision score of 0.76, we have reduced the amount of false positives substantially, from our initial score of 0.73 with logistic regression.\n",
    "\n",
    "Our accuracy also increased, which means that we are getting a larger amount of our test set correct, and not just getting less false positives. Our model performs better as a whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69388760",
   "metadata": {},
   "source": [
    "# Training Third Model, ANN\n",
    "\n",
    "Since ANN is computationally extensive, I am opting not to implement gridsearch, since it will increase the complexity of our code since we need to create a separaate model builder function to work with gridsearch, and also would take long to train + test due to the different parameters and combinations gridsearch would use.\n",
    "\n",
    "Instead, I am opting to use relu for hidden layers, and then for our final output layer, a sigmoid unit. This is similar to the approach we took in our homework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdba887e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_id           float64\n",
       "Size           float64\n",
       "Weight         float64\n",
       "Sweetness      float64\n",
       "Crunchiness    float64\n",
       "Juiciness      float64\n",
       "Ripeness       float64\n",
       "Acidity        float64\n",
       "Quality        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9e7ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 9)                 72        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 15)                150       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238\n",
      "Trainable params: 238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 1/88 [..............................] - ETA: 23s - loss: 0.6898 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 20:31:10.846940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6212 - accuracy: 0.6746\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.7346\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7311\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5203 - accuracy: 0.7404\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.7404\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5181 - accuracy: 0.7379\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.7418\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7393\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5190 - accuracy: 0.7389\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5191 - accuracy: 0.7400\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.7421\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5210 - accuracy: 0.7396\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5186 - accuracy: 0.7389\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7439\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5202 - accuracy: 0.7411\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7375\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5247 - accuracy: 0.7350\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5273 - accuracy: 0.7314\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5238 - accuracy: 0.7425\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5295 - accuracy: 0.7382\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5263 - accuracy: 0.7332\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7393\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7393\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7254\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5562 - accuracy: 0.7229\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.7368\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5318 - accuracy: 0.7446\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.7371\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7286\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.7314\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.7393\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7261\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5389 - accuracy: 0.7425\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7246\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5515 - accuracy: 0.7239\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.7154\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5543 - accuracy: 0.7329\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7289\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7211\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5487 - accuracy: 0.7271\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5542 - accuracy: 0.7261\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5978 - accuracy: 0.7032\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5398 - accuracy: 0.7332\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5554 - accuracy: 0.7211\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5614 - accuracy: 0.7236\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5502 - accuracy: 0.7246\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5738 - accuracy: 0.7157\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.7275\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5472 - accuracy: 0.7293\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6441 - accuracy: 0.6929\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5655 - accuracy: 0.7164\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5633 - accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5804 - accuracy: 0.7136\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5618 - accuracy: 0.7146\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6081 - accuracy: 0.7014\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.7161\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.7271\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6361 - accuracy: 0.7050\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.6375 - accuracy: 0.7029\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 0.5986 - accuracy: 0.7018\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5648 - accuracy: 0.7250\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.7289\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5596 - accuracy: 0.7246\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5775 - accuracy: 0.7146\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5597 - accuracy: 0.7211\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6129 - accuracy: 0.7018\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5659 - accuracy: 0.7214\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5511 - accuracy: 0.7257\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6584 - accuracy: 0.6871\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5528 - accuracy: 0.7254\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6306 - accuracy: 0.6964\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6023 - accuracy: 0.7014\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6219 - accuracy: 0.6993\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5940 - accuracy: 0.7207\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.7036\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6657 - accuracy: 0.6843\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.7293\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.7186\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5918 - accuracy: 0.7196\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6100 - accuracy: 0.6993\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5764 - accuracy: 0.7075\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6168 - accuracy: 0.7050\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5828 - accuracy: 0.7111\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6435 - accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6247 - accuracy: 0.6979\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5863 - accuracy: 0.7075\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6012 - accuracy: 0.7093\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5602 - accuracy: 0.7161\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.6011 - accuracy: 0.7054\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5792 - accuracy: 0.7061\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.6986\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5918 - accuracy: 0.7054\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.5987 - accuracy: 0.7064\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6248 - accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.5759 - accuracy: 0.7211\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.5930 - accuracy: 0.7111\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6248 - accuracy: 0.6996\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6379 - accuracy: 0.6882\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 0.6256 - accuracy: 0.6950\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 0.6191 - accuracy: 0.7114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bf2fab90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, activation='relu', input_shape=(7,)))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))   \n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1093e987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7425\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 20:33:31.116422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "yPredict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e16d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5376683 ]\n",
      " [0.8730905 ]\n",
      " [0.9414666 ]\n",
      " ...\n",
      " [0.6869172 ]\n",
      " [0.45628667]\n",
      " [0.5662097 ]]\n"
     ]
    }
   ],
   "source": [
    "print(yPredict) # if > .5, make = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a20acc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.74       593\n",
      "         1.0       0.75      0.73      0.74       607\n",
      "\n",
      "    accuracy                           0.74      1200\n",
      "   macro avg       0.74      0.74      0.74      1200\n",
      "weighted avg       0.74      0.74      0.74      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalPredict = [1 if y > 0.5 else 0 for y in yPredict]\n",
    "#print(finalPredict)\n",
    "\n",
    "print(classification_report(y_test, finalPredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc0784",
   "metadata": {},
   "source": [
    "# ANN Results on Test\n",
    "Accuracy of 0.74\n",
    "Precision of 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119a2a0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The best model for our problem based on the testing completed, seems to be random forests. With a high accuracy of 0.89 and a precision of 0.89, this model best suited our needs.\n",
    "\n",
    "With such a high precision, we know that we are finding less false positives, which means that bad apples are not able to get through in our predictions, while our accuracy is also great, further proving that the model is not a fluke."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
